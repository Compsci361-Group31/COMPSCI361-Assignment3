{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419276b6",
   "metadata": {},
   "source": [
    "## Task 1: Exploratory Data Analytics\n",
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cbc14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from matplotlib import pyplot as plt    #For plotting.\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")            #Can include stop words here\n",
    "\n",
    "def extract_features(fitting_var):\n",
    "    cv_all_articles = CountVectorizer()\n",
    "    cv_all_articles.fit(fitting_var)\n",
    "    vec = cv_all_articles.transform(fitting_var)\n",
    "    matrix = vec.toarray()              #Each row an article, each column a word.\n",
    "    word_bank = cv_all_articles.get_feature_names_out()\n",
    "    frequencies = matrix.sum(axis=0)    #Each column represents the frequency of a word in our articles\n",
    "    return matrix, word_bank, frequencies\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(matrix)\n",
    "# print(word_bank)\n",
    "# print(frequencies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab591c0",
   "metadata": {},
   "source": [
    "### Task 1 A\n",
    "#### Report number of articles, number of extracted features and 5 example articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33e554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get five example articles (Q1 a))\n",
    "\n",
    "whole_matrix, whole_word_bank, whole_frequencies = extract_features(train_df['Text'])\n",
    "\n",
    "print(\"Number of articles: \", whole_matrix.shape[0])\n",
    "print(\"Number of features: \", whole_matrix.shape[1])\n",
    "\n",
    "for i in range(5):\n",
    "    matrix, word_bank, frequencies = extract_features([train_df['Text'][i]])\n",
    "    print(f\"Article: {i+1} has features \\n{word_bank}\\n\\n\")\n",
    "    print(word_bank.size)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c3297",
   "metadata": {},
   "source": [
    "### Task 1 B\n",
    "#### i) Top 50 Frequency plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5470ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the top 50 terms in the entire dataset\n",
    "indices_50 = whole_frequencies.argsort()[-50:][::-1] #Get the indices of the top 50 terms\n",
    "print(indices_50)\n",
    "\n",
    "top_50_features = whole_word_bank[indices_50] #Get the top 50 features\n",
    "top_50_feature_frequencies = whole_frequencies[indices_50] #Get the frequencies of the top 50 features\n",
    "\n",
    "print(\"Rank. word: frequency\")\n",
    "for i in range(top_50_features.size):\n",
    "    print(f\"{i+1}. {top_50_features[i]}: {top_50_feature_frequencies[i]}\") #Print the top 50 features and their frequencies\n",
    "\n",
    "#Now we can plot the top 50 features with their frequencies\n",
    "plt.plot()\n",
    "\n",
    "plt.plot([i+1 for i in range(50)], top_50_feature_frequencies, linestyle = ':', marker='o', color=\"r\", label=\"Data Point\")\n",
    "plt.xlabel('ith most frequent word')\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.title(\"Frequency of the fifty most frequent words in the dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9d565f",
   "metadata": {},
   "source": [
    "#### ii) Frequency distribution for features for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b54f1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for task 1 b/ii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9241f1b",
   "metadata": {},
   "source": [
    "#### iii) Class distribution - plot frequency of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5741f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for task 1 b/iii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5544b044",
   "metadata": {},
   "source": [
    "## Task 2: Classification Models Learning\n",
    "### Task 2 A\n",
    "#### Naive Bayes Classifier\n",
    "#### i) Report top 20 most identifiable words that are most likely to occur in the articles over two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b6fe009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for task 2 a/i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57301fec",
   "metadata": {},
   "source": [
    "#### ii) Report the top 20 words that maximise the the probability quantity P(Xw = 1|Y = y)/P(Xw = 1| Y != y). Which list of words describe the 2 classes better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5399c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for task 2 a/ii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9aa1fc",
   "metadata": {},
   "source": [
    "### Task 2 B\n",
    "#### K-Nearest Neighbours Classifier\n",
    "#### Report surface plot of the kNN with your choice of hyperparameters k and distance metric. Explain the impact of k and the distance metric on the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c73293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# load data\n",
    "train_df = pd.read_csv('train.csv', header=None, names=['id', 'text', 'label'])\n",
    "test_df = pd.read_csv('test.csv', header=None, names=['id', 'text', 'label'])\n",
    "\n",
    "# vectorize text using TF-IDF \n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_df['text'])\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "\n",
    "y_train = train_df['label']\n",
    "y_test = test_df['label']\n",
    "\n",
    "# train kNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# predict and evaluate \n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Convert to dense and apply PCA for 2D visualization\n",
    "X_train_dense = X_train.toarray()\n",
    "pca = PCA(n_components=2)\n",
    "X_train_2d = pca.fit_transform(X_train_dense)\n",
    "\n",
    "# Convert string labels to numeric for plotting\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_numeric = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Function to create surface plot\n",
    "def create_surface_plot(X_2d, y_numeric, k_val, distance_metric):\n",
    "    knn_2d = KNeighborsClassifier(n_neighbors=k_val, metric=distance_metric)\n",
    "    knn_2d.fit(X_2d, y_numeric)\n",
    "    \n",
    "    # Create mesh for decision boundary\n",
    "    h = 0.1\n",
    "    x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
    "    y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    Z = knn_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap='RdYlBu')\n",
    "    plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_numeric, cmap='RdYlBu', edgecolors='black')\n",
    "    plt.colorbar()\n",
    "    plt.title(f'kNN Surface Plot (k={k_val}, metric={distance_metric})')\n",
    "    plt.xlabel('First Principal Component')\n",
    "    plt.ylabel('Second Principal Component')\n",
    "    plt.show()\n",
    "\n",
    "# Create surface plots with different hyperparameters\n",
    "create_surface_plot(X_train_2d, y_train_numeric, 3, 'euclidean')  # Small k\n",
    "create_surface_plot(X_train_2d, y_train_numeric, 15, 'euclidean') # Large k\n",
    "create_surface_plot(X_train_2d, y_train_numeric, 5, 'manhattan')  # Different metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f513425",
   "metadata": {},
   "source": [
    "### Task 2 C\n",
    "#### Support Vector Machines\n",
    "#### i) Soft margin linear kernel SVM\n",
    "#### Report surface plot and explain the impact of the penalty C hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0b4d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for task 2 C soft margin linear kernel svm\n",
    "# for surface plots check note on assignment pdf at bottom of task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122f3b2d",
   "metadata": {},
   "source": [
    "#### ii) Hard margin RBF kernel SVM\n",
    "#### Report surface plot and explain the impact of the kernel width hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9110cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for task 2 C hard margin rbf kernel svm\n",
    "# for surface plots check note on assignment pdf at bottom of task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8095514",
   "metadata": {},
   "source": [
    "### Task 2 D\n",
    "#### Neural Network\n",
    "#### add more details later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0afb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for task 2 D neural network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
